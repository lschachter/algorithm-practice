{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hashmap From Scratch**\n",
    "Design HashMap: Design a HashMap without using any built-in hash table libraries.\n",
    "NOTE: All keys and values will be in the range of [0, 1000000].\n",
    "      The number of operations will be in the range of [1, 10000].\n",
    "\n",
    "We're given the max number of inputs (maxSize = 10000) so I'm inclined twoards a single array\n",
    "using linear probing. A TON of wasted space on smaller inputs, but generally better\n",
    "performance than separate chaining. \n",
    "So we need an array of size 10000. try key % maxSize, if in use, linear probe for slot\n",
    "keep track of size so that if size == maxSize, can't put new data in.\n",
    "must keep track of where data has been deleted so that if key x needed linear probe for insertion,\n",
    "then the item in the previous space was removed, looking for x will continue beyond the first slot\n",
    "so when you delete, leave -1. \n",
    "\n",
    "Average runtime should be O(1) for each operation, getting worse (trending towards O(n)) as the\n",
    "map gets fuller. O(N) space, where N is the max size of the array, not the number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHashMap:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        \"\"\"\n",
    "        self.maxSize = 10000\n",
    "        self.table = [None] * self.maxSize\n",
    "        self.size = 0\n",
    "        \n",
    "    def getIndex(self, key: int) -> int:\n",
    "        \"\"\"\n",
    "        returns index for given key, or -1 if not there and table is full\n",
    "        keep track of checks: if you've checked every slot, return -1\n",
    "        \"\"\"\n",
    "        index = key % self.maxSize\n",
    "        checks = 0\n",
    "        while self.table[index]:\n",
    "            if self.table[index] != -1 and self.table[index][0] == key:\n",
    "                return index\n",
    "            if checks == self.maxSize:\n",
    "                return -1\n",
    "            index  = (index + 1) % self.maxSize\n",
    "            checks += 1\n",
    "        return -1\n",
    "\n",
    "    def put(self, key: int, value: int) -> None:\n",
    "        \"\"\"\n",
    "        value will always be non-negative.\n",
    "        \"\"\"\n",
    "        if self.size == self.maxSize:\n",
    "            return\n",
    "        index = key % self.maxSize\n",
    "        while self.table[index] and self.table[index] != -1 and self.table[index][0] != key:\n",
    "            index  = (index + 1) % self.maxSize\n",
    "        self.table[index] = (key, value)\n",
    "        self.size += 1\n",
    "        \n",
    "    def get(self, key: int) -> int:\n",
    "        \"\"\"\n",
    "        Returns the value to which the specified key is mapped, or -1 if this map contains no mapping for the key\n",
    "        \"\"\"\n",
    "        index = self.getIndex(key)\n",
    "        if index == -1:\n",
    "            return -1\n",
    "        return self.table[index][1]\n",
    "        \n",
    "\n",
    "    def remove(self, key: int) -> None:\n",
    "        \"\"\"\n",
    "        Removes the mapping of the specified value key if this map contains a mapping for the key\n",
    "        \"\"\"\n",
    "        if self.size == 0:\n",
    "            return\n",
    "        index = self.getIndex(key)\n",
    "        if index != -1:\n",
    "            self.table[index] = -1\n",
    "            self.size -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find First Unique Character**\n",
    "Given a string, find the first non-repeating character in it and return it's index. If it doesn't\n",
    "exist, return -1.\n",
    "    \n",
    "Frequency counts should always be dicts! but here I want to do this in one pass, so the dict\n",
    "should track not only frequncy of each letter, but also it's first appearance in the string.that\n",
    "way once we have the frequencies, we can loop through the keys in the dict instead of the letters\n",
    "in the string, which will usually have duplicates and therefore be a longer loop.\n",
    "~~~~\n",
    "                  # index, freq\n",
    "s = \"leetcode\" {'l': [0, 1], 'e': [1, 1X 2], 't': [3, 1]} etc ==>\n",
    "{'l': [0, 1], 'e': [1, 3], 't': [3, 1], 'c': [4, 1], 'o': [5, 1], 'd': [6, 1]}\n",
    "now we can loop through the dict, keeping track of the min index of letters that appear once.\n",
    "~~~~\n",
    "we need to go through each letter at least once, so O(n) minimum runtime. Ours loops twice so \n",
    "O(n + n) ==> O(n) and upper bound of O(n) space (in the case of every letter being unique, hits\n",
    "the upper bound, but always affected directly by n regardless). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstUniqChar:\n",
    "    def firstUniqChar(self, s: str) -> int:\n",
    "        import math\n",
    "        chars = {}\n",
    "        lenS = len(s)\n",
    "        for i in range(lenS):\n",
    "            if s[i] in chars:\n",
    "                chars[s[i]][1] += 1\n",
    "            else:\n",
    "                chars[s[i]] = [i, 1]\n",
    "        minI = math.inf\n",
    "        for char in chars:\n",
    "            if chars[char][1] == 1 and chars[char][0] < minI:\n",
    "                minI = chars[char][0]\n",
    "        if minI == math.inf:\n",
    "            return -1\n",
    "        return minI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intersection**\n",
    "Given two arrays, write a function to compute their intersection.\n",
    "ex: nums1 = [1,2,2,1], nums2 = [2,2] ==> Output: [2]\n",
    "\n",
    "Is it cheating to use set intersection? if not, i think the fastest possible answer is\n",
    "return list(set(nums1).intersection(nums2)) (runtime-wise, not just code length)\n",
    "\n",
    "But it probably is cheating. I'd like to use a set to keep track regardless, but if that's\n",
    "also cheating, a dictionary that, instead of keeping track of frequencies, will only be added to\n",
    "if num not in dict: ... but legit that's a set so...\n",
    "\n",
    "either way, we want to get the smaller list because that already limits the outcome, and loop\n",
    "through it. for each num, if that num is in the bigger list, add it to the set.\n",
    "\n",
    "this is worst case O(n * m) when there is no overlap between the lists. but this is dumb, just use\n",
    "set intersection (which has the same worst case runtime). space is O(n) for the overlap set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intersection:\n",
    "    def intersection(self, nums1: List[int], nums2: List[int]) -> List[int]:\n",
    "        overlap = set()\n",
    "        if len(nums2) < len(nums1):\n",
    "            nums1, nums2 = nums2, nums1\n",
    "            \n",
    "        for num in nums1:\n",
    "            if num in nums2:\n",
    "                overlap.add(num)\n",
    "        return list(overlap)\n",
    "    \n",
    "        # but don't do this, just do return list(set(nums1).intersection(nums2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LRU Cache**\n",
    "Design and implement a data structure for Least Recently Used (LRU) cache. It should support the\n",
    "following operations:\n",
    "get(key) - Get the value (will always be positive) of the key if the key exists in the cache,\n",
    "otherwise return -1.\n",
    "put(key, value) - Set or insert the value if the key is not already present. When the cache\n",
    "reached its capacity, it should invalidate the least recently used item before inserting a new\n",
    "item.\n",
    "The cache is initialized with a positive capacity.\n",
    "Could you do both operations in O(1) time complexity?\n",
    "\n",
    "ok so we need to make a hashmap again for O(1) runtime in both methods. but now each key must\n",
    "track both a value and its last access. so almost a combination of making your own hashmap and\n",
    "finding the first unique character in a string. so for putting, you must keep track of if slot is\n",
    "the key you're looking for, if slot is empty, and the index of the least recently used element.\n",
    "so that if you get through all slots and don't find the key or an empty slot, you don't have\n",
    "to search again for the index to write over. this is still O(N) where N = the size of the array,\n",
    "but not n the number of inputs, and still average case O(1). \n",
    "\n",
    "I initially tried to implement this the same way as building a hashmap, with an array the size of\n",
    "the capacity and then tracking the lru element and lruIndex to overwrite when full. However this\n",
    "led to a `time limit exceeded` error from leetcode. I had felt like using a dictionary would be \n",
    "cheating (in the same way it would have been when building your own hashmap), but it turns out\n",
    "it's the only way. Ordered Dicts are perfectly designed for this problem, so it ended up being\n",
    "quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRUCache:\n",
    "    def __init__(self, capacity: int):\n",
    "        from collections import OrderedDict\n",
    "        self.cache = OrderedDict()\n",
    "        self.cap = capacity\n",
    "        self.used = 0\n",
    "\n",
    "    def get(self, key: int) -> int:\n",
    "        if key in self.cache:\n",
    "            val = self.cache.pop(key)\n",
    "            self.cache[key] = val\n",
    "            return val\n",
    "        return -1\n",
    "\n",
    "    def put(self, key: int, value: int) -> None:\n",
    "        if key in self.cache:\n",
    "            self.cache.pop(key)\n",
    "            self.cache[key] = value\n",
    "        elif self.used < self.cap:\n",
    "            self.cache[key] = value\n",
    "            self.used += 1\n",
    "        else:\n",
    "            self.cache.popitem(last=False)\n",
    "            self.cache[key] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alien Dictionary**\n",
    "In an alien language, surprisingly they also use english lowercase letters, but possibly in a\n",
    "different order. The order of the alphabet is some permutation of lowercase letters.\n",
    "Given a sequence of words written in the alien language, and the order of the alphabet, return\n",
    "true if and only if the given words are sorted lexicographicaly in this alien language.\n",
    "\n",
    "first off, we're going to have to continuously check the alphabet for ordering, so we should \n",
    "minimize the cost of that by turning that into a dictionary (O(n) to create once, but O(1) to\n",
    "check in each comparison). so now for actually checking the order. we need to compare each word\n",
    "to the one next to it. if at any point something is in the wrong order, return false. if it's\n",
    "clearly in the right order (word1[x] < word2[x], NOT if they're equal), we can break out of the\n",
    "loop cuz they're good to go. but how to check if they're the same? i want to keep a boolean flag\n",
    "of same = True, and then if we break cuz it's correct, set same = False first. if same and\n",
    "len(word1) > len(word2) we can also return False. if we get all the way through, return true.\n",
    "~~~~\n",
    "ex [\"wor\", \"word\", \"world\"] \"worldabcefghijkmnpqstuvxyz\"\n",
    "     +++    +++  # same is true but len(word1) < len(word2) so keep going\n",
    "            +++X    +++X # d > l in order, return false\n",
    "~~~~\n",
    "the runtime is O(n) to make the hashmap  + O(n) for the outer loop * O(m) where m = len(word) so\n",
    "O(n + n*m) --> O(n*m).\n",
    "space is O(x) where x = len(order) for the dict, so O(n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlienDict:\n",
    "    def isAlienSorted(self, words: List[str], order: str) -> bool:\n",
    "        n  = len(words)\n",
    "        if n <= 1: return True\n",
    "        alph = {order[i]: i for i in range(len(order))}\n",
    "        for i in range(n - 1):\n",
    "            word1, word2 = words[i], words[i + 1]\n",
    "            m = min(len(word1), len(word2))\n",
    "            same = True\n",
    "            for j in range(m):\n",
    "                if alph[word1[j]] > alph[word2[j]]:\n",
    "                    return False\n",
    "                if alph[word1[j]] < alph[word2[j]]:\n",
    "                    same = False\n",
    "                    break\n",
    "            if same and len(word1) > len(word2): return False\n",
    "        return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
